{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i1.wp.com/numfocus.org/wp-content/uploads/2016/07/pandas-logo-300.png?fit=300%2C300&ssl=1\" width=\"200\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a solid understanding of Numpy, we can notice 2 things:\n",
    "1. Numpy is extremely useful for working with numerical values of the same type.\n",
    "1. Numpy is missing some flexibility when it comes to working with data which contains heterogeneous data (say, strings along side floats), as well as preforming some more data science related operations such as groupings and pivots.\n",
    "\n",
    "So we would like a way to benefit from numpy ability to work efficiently with numerical values, but, also enjoy some flexibility which will allow us to work with heterogeneous data. You might guess the answer by now : __Pandas__ (Named is derived from *Panel Data* which is multi-dimensional data involving measurements over time) \n",
    "\n",
    "## Hello Pandas\n",
    "***\n",
    "Pandas is a python module which builds on top of numpy capabilities, harvesting its numerical efficiency while enabling us to work with heterogeneous data. It does so by wrapping the ndarrays with it's own objects : pandas Dataframe and pandas Series which we will discuss after we import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # It is always advised to import numpy when working with pandas\n",
    "import pandas as pd # The official alias of pandas is pd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Objects\n",
    "Pandas supply 3 objects for us to work with : \n",
    "1. __Index__\n",
    "1. __Series__\n",
    "1. __DataFrame__  \n",
    "The reason for this order is because each series object contains a Index, and each DataFrame contains both Series objects and an Index object. But, we will talk about them in this order : Series, DataFrame, Index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series\n",
    "***\n",
    "<img src=\"https://www.straightpokersupplies.com/media/catalog/product/cache/1/image/1200x1200/9df78eab33525d08d6e5fb8d27136e95/w/o/world-series-of-poker-playing-cards-modiano-2015-16.jpg\" width=\"200\">\n",
    "\n",
    "The first object we are going to discuss is the pandas Series. A series is a \"wrapped\" __1d__ numpy array. Let's start with creating our very first pandas Series :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], name='random stuff') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0], s[1], s[2], s[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1:3] # Slicing works as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so when we print our series we see that the values it contains plus the index of each value.  \n",
    "Let's jump back to numpy for a second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([10, 20, 30, 40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0], a[1], a[2], a[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series can only be __1 dimensional__!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.Series(np.zeros((2, 2))) # this thorws an exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, at first glance it looks like the only difference between a series and a numpy array is the fact that the index is printed for us. And the truth is, that this is the major difference - the index.  \n",
    "A series object contains 2 objects as attributes: \n",
    "1. __values__ - a numpy array of values.\n",
    "1. __index__ - a pandas Index object. (guess what holds the values under the hood? a numpy array)  \n",
    "\n",
    "Let's explore:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_values, s_index = s.values, s.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_values, s_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(s_values), type(s_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we see that the values attribute is a numpy array and that the index is a RangeIndex object (This is a sub class of pandas Index object which we will talk about soon).  \n",
    "This means that unlike numpy which sets an implicit index, in a series we can explicitly set an index. Let's see this in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 40], index=list('abcd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we understand why printing the index makes sense. What's more, we can use the index to access the values in our series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['a'], s['b'], s['c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slicing work here as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['a':'c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, we did not lose our previous capabilities and we can still access our elements using a numeric index. This comes with a caveat we will soon see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Danger__. Be careful with mixing explicit indices and implicit indices as in some cases this could cause confusion. the worst scenario is when you set a different numeric index to your series because then you can not use the implicit indexing anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([10, 20, 30, 30], index=range(1, 5))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[0] # This throws a long error which I don't want to pollute the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1] # Some might expect this to give the 2nd value in the array while it will give the second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to look at pandas series is as a sort of python dictionary. Where the index is the keys and the values are, well, the values.  \n",
    "This similarity is so apparent that you can use python dictionaries to build pandas series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\n",
    "    'dollar' : 3.14,\n",
    "    'euro'   : 3.5,\n",
    "    'pound'  : 4.29\n",
    "}\n",
    "s = pd.Series(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['dollar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['euro':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.keys(), s.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Summing up__ : A pandas series is a enhanced 1d numpy array which enables us explicit indexing setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Exercise\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a series of size 10 with random values and an implicit index__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create the following series: (index on left, values on the right)__\n",
    "```py\n",
    "2     1\n",
    "4     3\n",
    "6     5\n",
    "8     7\n",
    "10    9\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = None\n",
    "# Your code starts here\n",
    "\n",
    "# Your code ends here\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Use slicing to access the values of `a` with index 4 and 8.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create the following series(index on the left, values on the right)__\n",
    "```py\n",
    "2squared     4\n",
    "3squared     9\n",
    "4squared    16\n",
    "5squared    25\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "***\n",
    "\n",
    "<img src=\"https://www.tutorialspoint.com/python_pandas/images/structure_table.jpg\" width=\"300\">\n",
    "\n",
    "A pandas dataframe is basically $n$ pandas series stacked vertically(They are the columns) one next to each other. Think of a dataframe as basically an excel sheet where you can name you columns. Another option is to think of it as an enhanced 2d numpy array, where you can access the column and the rows in a \"fancy\" way.  \n",
    "Let's explore :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randint(low=10, high=50, size=(15, 3))\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access each column by it's name :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And each columns is a pandas series as we mentioned above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['A']), type(df['B']), type(df['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And as mentioned above each of these series contains a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df['A'].values), type(df['B'].values), type(df['C'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We mentioned earlier we can view the pandas series as a dictionary, mapping from index to value. We can also think of a dataframe as a dictionary mapping from index (Column name) to a series.  \n",
    "This helps in remember the following : When we use the square brackets notation to access elements in our dataframe we get back a Series. (some might expect to get a row, so don't be that person).\n",
    "\n",
    "The dataframe object also contains yet another Index object, which maps to the dataframe rows. we will see how we use these to access the rows later on.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df.index), type(df.columns), type(df.values[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Exercise\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create the following dataframe__\n",
    "```py\n",
    "\t A\t B\t C\t D\t E\n",
    "0\t0\t 1\t 2\t 3\t 4\n",
    "1\t5\t 6\t 7\t 8\t 9\n",
    "2\t10\t11\t12\t13\t14\n",
    "3\t15\t16\t17\t18\t19\n",
    "4\t20\t21\t22\t23\t24\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create the following dataframe__\n",
    "```py\n",
    "\t0\t1\t2\t3\t4\n",
    "0\tA\tB\tC\tD\tE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create the following dataframe__:\n",
    "```py\n",
    "\tIsrael\tUSA\tJapan\n",
    "first\t0\t1\t2\n",
    "second\t3\t4\t5\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index\n",
    "*** \n",
    "\n",
    "<img src=\"https://ecuinc.biz/wp-content/uploads/2017/11/index.jpg\" width=\"200\">\n",
    "\n",
    "We just saw each of our object uses the pandas index. We can think of the pandas index as an immutable numpy array. Meaning, we can perform on the index object a lot of the operations we used on the numpy array, __BUT__,  we can't  change any of the values (which makes sense for an Index). (In other words, An Index is an immutable object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.Index([1, 2, 3, 4, 5, 6, 7, 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.shape, idx.ndim, idx.size, idx.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use a lot of the same techniques to access elements in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx[0], idx[1:5], idx[::2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But, since this is an immutable object we can not change the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx[0] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And guess what the Index object contains under the hood? (You guessed it! a numpy array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(idx.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A great functionality of the Index object is it supports set operations. We can preform various set operation between indices to great new indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some set operation remainder:  \n",
    "\n",
    "* __Union__        : $A \\cup B = \\{a | a\\in A ~or~ a\\in B \\}$ All the elements which are either in A or in B.  \n",
    "* __Intersection__ : $A \\cap B = \\{a | a\\in A ~and~ a\\in B \\}$ All the elements which are both in A and in B.  \n",
    "* __Symmetric difference__ : $A \\triangle B = \\{a | a \\in A ~or~ a\\in B~ but ~not ~both \\}$\n",
    "\n",
    "And the operators in python:  \n",
    "* __Union__ - |  \n",
    "* __Intersection__ - &  \n",
    "* __Symmetric Difference__ - ^  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see that in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_1 = pd.Index(np.arange(10))\n",
    "ind_2 = pd.Index(np.arange(5, 12))\n",
    "ind_1, ind_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_1 | ind_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_1 & ind_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_1 ^ ind_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most of the scenario you will encounter there will not be a need to construct an index object outside a Series or a Dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get all the values which in ind_1 minus those in ind_2__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_1 = pd.Index(np.arange(10))\n",
    "ind_2 = pd.Index(np.arange(5, 12))\n",
    "\n",
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the indices which are either in `ind_1` and `ind_2` but not in `ind_3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_1 = pd.Index(np.arange(0, 10, 2))\n",
    "ind_2 = pd.Index(np.arange(1, 11, 2))\n",
    "ind_3 = pd.Index(np.arange(0, 11, 3))\n",
    "\n",
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing elements\n",
    "***\n",
    "\n",
    "### Series\n",
    "We talked about the fact the a series is similar to 2 different objects : a 1d numpy array and a dictionary.  \n",
    "So we know we can access elements in the same way we access elements in each of those objects.  \n",
    "But there are some nuances we should pay attention to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series(np.arange(1, 5), list('bcde'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing like a numpy array :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[1], s[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing like a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s['e'], s['b':'d'] # Notice this does tkae the last element!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the way, slicing does not work for python dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {l:i for i, l in zip(range(5), list('abcde'))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['a':'d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can start getting 'fancy' with our Series with much of what we saw for numpy.  \n",
    "We can pass use boolean indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2611)\n",
    "s = pd.Series(np.random.randint(low=0, high=20, size=10))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = s[s>6]\n",
    "x.loc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[(s<6) | (s > 17)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can get fancy as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2611)\n",
    "index_lettters = [chr(ord('a') + i) for i in range(10)]\n",
    "s = pd.Series(np.random.randint(low=0, high=20, size=10), index=index_lettters)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[['a', 'd', 'e']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[[0, 3, 4]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget you can use both the defined index an numeric indices when your defined index is not numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### loc and iloc \n",
    "As you might notice, the fact that we can use both the implicit and explicit index can cause confusion.  \n",
    "If you want to make sure that both you and the person reading your code knows which index you are referring to you can use the __loc__ and __iloc__ methods.\n",
    "* __iloc__ - refers to the numeric index\n",
    "* __loc__ - refers to the explicit index.  \n",
    "If your explicit index is the same as the implicit index this 2 methods will return similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2611)\n",
    "index_lettters = [chr(ord('a') + i) for i in range(10)]\n",
    "s = pd.Series(np.random.randint(low=0, high=20, size=10), index=index_lettters)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.iloc[[1, 2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.loc['a':'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will cause and exception.\n",
    "s.loc[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will cause an exception.\n",
    "s.iloc['a':'d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame\n",
    "As we saw earlier its easy to think of a DataFrame as a dictionary mapping between index and columns, and as we saw we can access column in a dictionary like bracket notion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1010)\n",
    "index_lettters = [chr(ord('a') + i) for i in range(10)]\n",
    "data = np.random.randint(low=0, high=100, size=(10, 3))\n",
    "df = pd.DataFrame(data, columns=['A', 'B', 'C'], index=index_lettters)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['A']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the question arises - how do we access rows in our dataframes? And the answer is through the loc and iloc methods. In a dataframe those methods refers to the rows only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the 2nd and 3rd row\n",
    "df.iloc[[2, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a loc example as well:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[['a', 'b', 'c']],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, So if you think you are starting to get the hang of it. Now let's get you confused.  \n",
    "If you use slicing or boolean mask using the bracket notion, this will work on the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media0.giphy.com/media/3oz8xZvvOZRmKay4xy/giphy.gif?cid=790b7611c7f9d5575bd5514b74f3bc3d9757e4daf8ae570f&rid=giphy.gif\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So slicing works on the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean masking works on the rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['A'] > 50 # Get rows where A value is bigger then 50\n",
    "df[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, fancy indexing does work on the columns :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['A', 'B']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Summarize : \n",
    "If you want to access the columns:\n",
    "- Standard dictionary like accessing work.\n",
    "- Fancy indexing given the same type as the columns index works as well.\n",
    "\n",
    "If you want to access the rows:\n",
    "- use iloc for implicit index.\n",
    "- use loc for explicit index.\n",
    "- use slicing using bracket notion.\n",
    "\n",
    "- use boolean masking using bracket notion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Exercise\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "index_lettters = [chr(ord('a') + i) for i in range(20)]\n",
    "df = pd.DataFrame(np.random.randint(10, 100, size=(20, 4)), \n",
    "                  columns=['House', 'Garden', 'Shed', 'Basement'],\n",
    "                  index=index_lettters)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Display the *House* and *Garden* Columns__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Display all the even rows__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Display all the rows where the *Garden* value is bigger than 50.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Display all the rows where either the *Shed* value is bigger than 50 or the Basement value is lower 50 but not both.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Display the 4, 8 and 10th row (don't use letters).__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Functions\n",
    "***\n",
    "We saw that numpy universal function is the magic sauce which gives us an amazing speed up when performing element wise operations. Since pandas uses numpy under the hood we want to leverage this functionality with pandas as well.\n",
    "When dealing with series, numpy ufuncs works as you expect, with the \"side effect\" that the index is preserved as is. As one would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each of the element was squared and our index stayed the same.  \n",
    "If you have a homogenous dataframe you can preform the same on datafrmaes as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.arange(20).reshape(4, 5))\n",
    "df * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the index stays the same while each element in the matrix is multiplied by 10.  \n",
    "\n",
    "If one of the columns is string, this will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_str = pd.concat((df, pd.Series(['a', 'b', 'c', 'd'])), axis=1)\n",
    "df_with_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_str ** 2 # This fails since we have a string column in our dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating on two pandas object\n",
    "If you try to preform an binary operation between 2 pandas objects, the operation will be based on the index and pandas will complete the result with nan in case an index appears in only one of the objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_a = pd.Series(np.arange(5), index=list('abcde'))\n",
    "ser_b = pd.Series(np.arange(5, 10), index=list('gfedc'))\n",
    "\n",
    "ser_a, ser_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_a / ser_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is a Series where the index is equal to the union of both index. Where both series had a value we get a float but where there was only one value we get a nan value, which is pandas way of indicating a missing value.  \n",
    "If you want to get a more reliable result you can use an explicit operation call and pass in the fill_value parameter which fill any missing value on either side of the series with the passed parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_a.div(ser_b, fill_value=1)  # If one of the values is missing preform the action with 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to perform an action between 2 dataframes the same logic takes place only this time the elements will be aligned on both the column index and the row index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = pd.DataFrame(np.arange(18).reshape(6,3), columns=['A', 'B', 'C'])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = pd.DataFrame(np.arange(4).reshape(2, 2) * 10, columns=['D', 'E'])\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A + B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we try to preform an action between a series and dataframe the alignment will be on the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_a = pd.Series([1, 2, 3], index=list('ABC'))\n",
    "ser_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A - ser_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Exercise\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1002)\n",
    "df_1 = pd.DataFrame(np.random.randint(0, 50, size=(20, 3)), columns=['Sunday', 'Monday', 'Tuesday'])\n",
    "df_2 = pd.DataFrame(np.random.randint(0, 50, size=(10, 3)), columns=['Sunday', 'Monday', 'Tuesday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get all the values from `df_1` Sunday column squared__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__get the value of `df_2` Monday + `df_1` Tuesday. Complete missing values on either side with 9.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Get all the rows from `df_2` where the *monday* value is bigger then the *monday* value of `df_1`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code starts here\n",
    "\n",
    "# Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenate and Append\n",
    "Again, going back to numpy, we can concatenate series and dataframes using the pandas concat method :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_a = pd.Series(np.arange(5))\n",
    "ser_b = pd.Series(np.arange(5, 10), index=np.arange(5, 10))\n",
    "ser_a, ser_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([ser_a, ser_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's important to know is that when concatenating objects, pandas concat keeps the indices of the original objects. This could cause some unwanted behavior and you should pay attention to these issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_a = pd.Series(np.arange(5))\n",
    "ser_b = pd.Series(np.arange(5, 10))\n",
    "pd.concat([ser_a, ser_b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do want the new object to have a new \"organized\" index you can use the ignore_index flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([ser_a, ser_b], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can concat dataframe as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(np.zeros((3, 2)), columns=['A', 'B'])\n",
    "df_2 = pd.DataFrame(np.ones((4, 2)), columns=['A', 'B'])\n",
    "pd.concat([df_1, df_2], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use append as we saw early on with lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.append(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "- [Python Data Science Handbook](https://jakevdp.github.io/PythonDataScienceHandbook/) A thorough tour into Numpy. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
